{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2825a697-1f89-4c34-a0e8-a1ab6384c241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thuva_siva29/green-software-foundation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-29 14:14:58.065541: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-29 14:14:58.514380: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-29 14:14:58.716134: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-29 14:14:58.717543: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-29 14:14:59.051614: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 14:15:00.372611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "import os\n",
    "from get_embedding_function import get_embedding_function\n",
    "from populate_database import setup_database\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "import pandas as pd\n",
    "from dspy.datasets.dataset import Dataset\n",
    "from dspy.evaluate.evaluate import Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9913efcc-d894-49ce-940f-91d8832c5ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Example({'question': 'Is there any mention of removing unused assets to optimize performance?', 'answer': 'No'}) (input_keys={'question'}), Example({'question': 'Is there any mention of optimizing average CPU utilization to ensure efficient use of resources?', 'answer': 'No'}) (input_keys={'question'}), Example({'question': 'Is there any mention of optimizing storage utilization to reduce energy consumption?', 'answer': 'Yes'}) (input_keys={'question'}), Example({'question': 'Is there any mention of minimizing the total number of deployed environments to save resources?', 'answer': 'No'}) (input_keys={'question'}), Example({'question': 'Is there any mention of scaling down Kubernetes applications when not in use to reduce resource usage?', 'answer': 'Not Applicable'}) (input_keys={'question'}), Example({'question': 'Is there any mention of managing peak CPU utilization to avoid over-provisioning?', 'answer': 'No'}) (input_keys={'question'}), Example({'question': 'Is there any mention of scaling down applications during idle periods to minimize resource usage?', 'answer': 'No'}) (input_keys={'question'})]\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = \"queries_judgements.csv\"\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, file_path, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        self._train = df.iloc[0:7].to_dict(orient='records')\n",
    "\n",
    "        self._dev = df.iloc[7:14].to_dict(orient='records')\n",
    "\n",
    "dataset = CSVDataset(TRAINING_DATA)\n",
    "\n",
    "trainset = [x.with_inputs('question') for x in dataset.train]\n",
    "devset = [x.with_inputs('question') for x in dataset.dev]\n",
    "\n",
    "print(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e887f959-a738-4fdb-a381-55ccb2dc3c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨  Database Cleared\n",
      "Number of existing documents in DB: 32\n",
      "✅ No new documents to add\n"
     ]
    }
   ],
   "source": [
    "CHROMA_PATH = os.getenv(\"CHROMA_PATH\")\n",
    "DOCUMENT_PATH=\"./documents/4.pdf\"\n",
    "\n",
    "emb_local = False\n",
    "\n",
    "setup_database(DOCUMENT_PATH, True, emb_local, True)\n",
    "\n",
    "embedder, collection_name = get_embedding_function(run_local=emb_local)\n",
    "\n",
    "retriever_model = ChromadbRM(\n",
    "    collection_name,\n",
    "    CHROMA_PATH,\n",
    "    embedding_function=embedder.embed,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "lm = dspy.OllamaLocal(model='phi3')\n",
    "\n",
    "dspy.settings.configure(lm=lm, rm=retriever_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f337eb58-63d4-45d3-b850-c42a9ed0bc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['these properties.\\n2. Capacity Estimation for Dropbox System Design\\nStorage Estimations:\\nAssumptions:', 'The total number of users = 500 million.\\nTotal number of daily active users = 100 million\\nThe average number of files stored by each user = 200\\nThe average size of each file = 100 KB\\nTotal number of active connections per minute = 1 million\\n\\nStorage Estimations:\\n\\nTotal number of files = 500 million * 200 = 100 billion\\nTotal storage required = 100 billion * 100 KB = 10 PB\\n\\n3. High-Level Design(HLD) of Dropbox System Design\\n\\n\\n-----\\n\\ncommunicates with the Upload Service on the server side. Large files may be broken into smaller chunks\\nfor efficient transfer.', '7. Scalabilty for Dropbox System Design\\nHorizontal Scaling\\nWe can add more servers behind the load balancer to increase the capacity of each service. This is\\nknown as Horizontal Scaling and each service can be independently scaled horizontally in our design.\\nDatabase Sharding\\nMetadata DB is sharded based on object_id. Our hash function will map each object_id to a random\\nserver where we can store the file/folder metadata. To query for a particular object_id, service can\\ndetermine the database server using same hash function and query for data. This approach will distribute\\nour database load to multiple servers making it scalable.\\nCache Sharding\\nSimilar to Metadata DB Sharding, we are distributing the cache to multiple servers. In-fact Redis has out']\n"
     ]
    }
   ],
   "source": [
    "retriever = dspy.Retrieve(k=3)\n",
    "print(retriever(\"Is there any mention of optimizing the size of AI/ML models to save storage space and reduce memory usage during inference\").passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70d50637-d017-46fc-b0f2-a5aaf90e6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Give a concrete yes or no or not applicable answer to a question based on the retrieved context.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"Output nothing else apart from either yes, no, or not applicable.\")\n",
    "\n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)\n",
    "\n",
    "#RAG().forward(query)\n",
    "#print(lm.inspect_history(n=1))\n",
    "       \n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0389d58-7c3c-4812-b85e-c255996ffb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "result = RAG().forward(\"Is there any mention of optimizing the size of AI/ML models to save storage space and reduce memory usage during inference?\")\n",
    "print(result.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31f99faa-1c22-4d2e-9a44-6647fd36cec2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Give a concrete yes or no or not applicable answer to a question based on the retrieved context.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: Output nothing else apart from either yes, no, or not applicable.\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «these properties.\n",
      "2. Capacity Estimation for Dropbox System Design\n",
      "Storage Estimations:\n",
      "Assumptions:»\n",
      "[2] «The total number of users = 500 million.\n",
      "Total number of daily active users = 100 million\n",
      "The average number of files stored by each user = 200\n",
      "The average size of each file = 100 KB\n",
      "Total number of active connections per minute = 1 million\n",
      "\n",
      "Storage Estimations:\n",
      "\n",
      "Total number of files = 500 million * 200 = 100 billion\n",
      "Total storage required = 100 billion * 100 KB = 10 PB\n",
      "\n",
      "3. High-Level Design(HLD) of Dropbox System Design\n",
      "\n",
      "\n",
      "-----\n",
      "\n",
      "communicates with the Upload Service on the server side. Large files may be broken into smaller chunks\n",
      "for efficient transfer.»\n",
      "[3] «7. Scalabilty for Dropbox System Design\n",
      "Horizontal Scaling\n",
      "We can add more servers behind the load balancer to increase the capacity of each service. This is\n",
      "known as Horizontal Scaling and each service can be independently scaled horizontally in our design.\n",
      "Database Sharding\n",
      "Metadata DB is sharded based on object_id. Our hash function will map each object_id to a random\n",
      "server where we can store the file/folder metadata. To query for a particular object_id, service can\n",
      "determine the database server using same hash function and query for data. This approach will distribute\n",
      "our database load to multiple servers making it scalable.\n",
      "Cache Sharding\n",
      "Similar to Metadata DB Sharding, we are distributing the cache to multiple servers. In-fact Redis has out»\n",
      "\n",
      "Question: Is there any mention of optimizing the size of AI/ML models to save storage space and reduce memory usage during inference?\n",
      "\n",
      "Reasoning: Let's think step by step in order to No, based on the provided context which focuses primarily on system design aspects such as capacity estimation, scalability through horizontal scaling, database sharding for metadata management, cache sharding using Redis, and file upload mechanisms. There is no mention of optimizing AI/ML model sizes or memory usage during inference in this specific text snippet from the Dropbox System Design document.\n",
      "\n",
      "Answer:\u001b[32m No\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(lm.inspect_history(n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52057d1d-dbb7-4796-ab5b-07f04ff6552d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████████████                                                                                                            | 1/7 [01:22<08:17, 82.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to run or to evaluate example Example({'question': 'Is there any mention of removing unused assets to optimize performance?', 'answer': 'No'}) (input_keys={'question'}) with <function validate_context_and_answer at 0x7f3e00acf740> due to Expected embeddings to be a list, got dict.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:18<00:00, 36.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 7  (42.9): 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [03:41<00:00, 31.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 7  (42.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/thuva_siva29/green-software-foundation/.venv/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:266: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['False' 'False' 'False' '✔️ [True]' '✔️ [True]']' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_97995 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_97995 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_97995_row0_col0, #T_97995_row0_col1, #T_97995_row0_col2, #T_97995_row0_col3, #T_97995_row0_col4, #T_97995_row1_col0, #T_97995_row1_col1, #T_97995_row1_col2, #T_97995_row1_col3, #T_97995_row1_col4, #T_97995_row2_col0, #T_97995_row2_col1, #T_97995_row2_col2, #T_97995_row2_col3, #T_97995_row2_col4, #T_97995_row3_col0, #T_97995_row3_col1, #T_97995_row3_col2, #T_97995_row3_col3, #T_97995_row3_col4, #T_97995_row4_col0, #T_97995_row4_col1, #T_97995_row4_col2, #T_97995_row4_col3, #T_97995_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_97995\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_97995_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_97995_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_97995_level0_col2\" class=\"col_heading level0 col2\" >context</th>\n",
       "      <th id=\"T_97995_level0_col3\" class=\"col_heading level0 col3\" >pred_answer</th>\n",
       "      <th id=\"T_97995_level0_col4\" class=\"col_heading level0 col4\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_97995_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_97995_row0_col0\" class=\"data row0 col0\" >Is there any mention of reducing transmitted data to save energy?</td>\n",
       "      <td id=\"T_97995_row0_col1\" class=\"data row0 col1\" >Yes</td>\n",
       "      <td id=\"T_97995_row0_col2\" class=\"data row0 col2\" >['The synchronization service receives the request from the request queue of the messaging services and\\nupdates the metadata database with the latest changes.\\nAlso, the synchronization service...</td>\n",
       "      <td id=\"T_97995_row0_col3\" class=\"data row0 col3\" >No</td>\n",
       "      <td id=\"T_97995_row0_col4\" class=\"data row0 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97995_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_97995_row1_col0\" class=\"data row1 col0\" >Is there any mention of allowing independent scaling of logical components?</td>\n",
       "      <td id=\"T_97995_row1_col1\" class=\"data row1 col1\" >Yes</td>\n",
       "      <td id=\"T_97995_row1_col2\" class=\"data row1 col2\" >['Scaling can be achieved using techniques such as vertical scaling (increasing hardware capabilities) or\\nhorizontal scaling (adding more machines).\\nHowever, horizontal scaling for relational databases often involves...</td>\n",
       "      <td id=\"T_97995_row1_col3\" class=\"data row1 col3\" >No, because the context discusses horizontal scaling for relational databases and does not specifically address the independence of scaling individual pieces of physical hardware like...</td>\n",
       "      <td id=\"T_97995_row1_col4\" class=\"data row1 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97995_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_97995_row2_col0\" class=\"data row2 col0\" >Is there any mention of using relevant metrics to dynamically adjust Kubernetes workloads?</td>\n",
       "      <td id=\"T_97995_row2_col1\" class=\"data row2 col1\" >Not Applicable</td>\n",
       "      <td id=\"T_97995_row2_col2\" class=\"data row2 col2\" >['7. Scalabilty for Dropbox System Design\\nHorizontal Scaling\\nWe can add more servers behind the load balancer to increase the capacity of each service. This is\\nknown as...</td>\n",
       "      <td id=\"T_97995_row2_col3\" class=\"data row2 col3\" >No</td>\n",
       "      <td id=\"T_97995_row2_col4\" class=\"data row2 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97995_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_97995_row3_col0\" class=\"data row3 col0\" >Is there any mention of scaling infrastructure based on real-time user demand?</td>\n",
       "      <td id=\"T_97995_row3_col1\" class=\"data row3 col1\" >No</td>\n",
       "      <td id=\"T_97995_row3_col2\" class=\"data row3 col2\" >['7. Scalabilty for Dropbox System Design\\nHorizontal Scaling\\nWe can add more servers behind the load balancer to increase the capacity of each service. This is\\nknown as...</td>\n",
       "      <td id=\"T_97995_row3_col3\" class=\"data row3 col3\" >No</td>\n",
       "      <td id=\"T_97995_row3_col4\" class=\"data row3 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_97995_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_97995_row4_col0\" class=\"data row4 col0\" >Is there any mention of setting storage retention policies to automatically clean up old data?</td>\n",
       "      <td id=\"T_97995_row4_col1\" class=\"data row4 col1\" >No</td>\n",
       "      <td id=\"T_97995_row4_col2\" class=\"data row4 col2\" >['request. We generally mention availability as 5 Nine’s, 4 Nine’s, etc. 5 Nine’s means 99.999% availability,\\n4 Nine means 99.99% availability, and so on.\\nDurability: Durability means...</td>\n",
       "      <td id=\"T_97995_row4_col3\" class=\"data row4 col3\" >No</td>\n",
       "      <td id=\"T_97995_row4_col4\" class=\"data row4 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f3e52dd14d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 2 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "42.86"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
    "\n",
    "compiled_rag = teleprompter.compile(RAG(), trainset=trainset)\n",
    "\n",
    "evaluate_on_dataset = Evaluate(devset=devset, num_threads=1, display_progress=True, display_table=5)\n",
    "\n",
    "#Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "evaluate_on_dataset(compiled_rag, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2058bd8b-70e2-4d47-8608-0d146ef8b51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Give a concrete yes or no or not applicable answer to a question based on the retrieved context.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Is there any mention of scaling down applications during idle periods to minimize resource usage?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of removing unused assets to optimize performance?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of minimizing the total number of deployed environments to save resources?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of scaling down Kubernetes applications when not in use to reduce resource usage?\n",
      "Answer: Not Applicable\n",
      "\n",
      "Question: Is there any mention of optimizing storage utilization to reduce energy consumption?\n",
      "Answer: Yes\n",
      "\n",
      "Question: Is there any mention of optimizing average CPU utilization to ensure efficient use of resources?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of managing peak CPU utilization to avoid over-provisioning?\n",
      "Answer: No\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: Output nothing else apart from either yes, no, or not applicable.\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «7. Scalabilty for Dropbox System Design\n",
      "Horizontal Scaling\n",
      "We can add more servers behind the load balancer to increase the capacity of each service. This is\n",
      "known as Horizontal Scaling and each service can be independently scaled horizontally in our design.\n",
      "Database Sharding\n",
      "Metadata DB is sharded based on object_id. Our hash function will map each object_id to a random\n",
      "server where we can store the file/folder metadata. To query for a particular object_id, service can\n",
      "determine the database server using same hash function and query for data. This approach will distribute\n",
      "our database load to multiple servers making it scalable.\n",
      "Cache Sharding\n",
      "Similar to Metadata DB Sharding, we are distributing the cache to multiple servers. In-fact Redis has out»\n",
      "[2] «Requirements Gathering for Dropbox System Design\n",
      "Capacity Estimation for Dropbox System Design\n",
      "High-Level Design(HLD) of Dropbox System Design\n",
      "Low-Level Design(LLD) of Dropbox System Design\n",
      "Database Design for Dropbox System Design\n",
      "API Design for Dropbox System Design\n",
      "Scalabilty for Dropbox System Design\n",
      "1. Requirements Gathering for Dropbox System Design\n",
      "Functional Requirements:\n",
      "The user should be able to upload photos/files.\n",
      "The user should be able to create/delete directories on the drive.\n",
      "The user should be able to download files\n",
      "The user should be able to share the uploaded files.\n",
      "The drive should synchronize the data between user all devices.\n",
      "Non Functional Requirements:\n",
      "Availability: Availability means what percentage of the time the system is available to take a user’s»\n",
      "[3] «3.8. Downloading Services:\n",
      "Clients initiate file download requests through the client application. The Download Service queries the\n",
      "Metadata Database for file details. The server’s Download Service retrieves metadata from the Metadata\n",
      "Database. Metadata includes information such as file name, size, owner, and access permissions.\n",
      "\n",
      "4. Low-Level Design(LLD) of Dropbox System Design\n",
      "A lot of people assume designing a Dropbox is that all they just need to do is to use some cloud services,\n",
      "upload the file, and download the file whenever they want but that’s not how it works. The core problem is\n",
      "“Where and how to save the files? “. Suppose you want to share a file that can be of any size (small or\n",
      "big) and you upload it into the cloud.»\n",
      "\n",
      "Question: Is there any mention of adopting serverless cloud services to optimize resource usage?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m Answer: No\n",
      "\n",
      "---\n",
      "\n",
      "Context: [1] «7. Scalabilty for Dropbox System Design\n",
      "Horizontal Scaling\n",
      "We can add more servers behind the load balancer to increase the capacity of each service. This is\n",
      "known as Horizontal Scaling and each service can be independently scaled horizontally in our design.\n",
      "Database Sharding\n",
      "Metadata DB is sharded based on object_id. Our hash function will map each object_id to a random\n",
      "server where we can store the file/folder metadata. To query for a particular object_id, service can\n",
      "determine the database server using same hash function and query for data. This approach will distribute\n",
      "our database load\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Give a concrete yes or no or not applicable answer to a question based on the retrieved context.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Is there any mention of scaling down applications during idle periods to minimize resource usage?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of removing unused assets to optimize performance?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of minimizing the total number of deployed environments to save resources?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of scaling down Kubernetes applications when not in use to reduce resource usage?\n",
      "Answer: Not Applicable\n",
      "\n",
      "Question: Is there any mention of optimizing storage utilization to reduce energy consumption?\n",
      "Answer: Yes\n",
      "\n",
      "Question: Is there any mention of optimizing average CPU utilization to ensure efficient use of resources?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of managing peak CPU utilization to avoid over-provisioning?\n",
      "Answer: No\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: Output nothing else apart from either yes, no, or not applicable.\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «7. Scalabilty for Dropbox System Design\n",
      "Horizontal Scaling\n",
      "We can add more servers behind the load balancer to increase the capacity of each service. This is\n",
      "known as Horizontal Scaling and each service can be independently scaled horizontally in our design.\n",
      "Database Sharding\n",
      "Metadata DB is sharded based on object_id. Our hash function will map each object_id to a random\n",
      "server where we can store the file/folder metadata. To query for a particular object_id, service can\n",
      "determine the database server using same hash function and query for data. This approach will distribute\n",
      "our database load to multiple servers making it scalable.\n",
      "Cache Sharding\n",
      "Similar to Metadata DB Sharding, we are distributing the cache to multiple servers. In-fact Redis has out»\n",
      "[2] «Requirements Gathering for Dropbox System Design\n",
      "Capacity Estimation for Dropbox System Design\n",
      "High-Level Design(HLD) of Dropbox System Design\n",
      "Low-Level Design(LLD) of Dropbox System Design\n",
      "Database Design for Dropbox System Design\n",
      "API Design for Dropbox System Design\n",
      "Scalabilty for Dropbox System Design\n",
      "1. Requirements Gathering for Dropbox System Design\n",
      "Functional Requirements:\n",
      "The user should be able to upload photos/files.\n",
      "The user should be able to create/delete directories on the drive.\n",
      "The user should be able to download files\n",
      "The user should be able to share the uploaded files.\n",
      "The drive should synchronize the data between user all devices.\n",
      "Non Functional Requirements:\n",
      "Availability: Availability means what percentage of the time the system is available to take a user’s»\n",
      "[3] «3.8. Downloading Services:\n",
      "Clients initiate file download requests through the client application. The Download Service queries the\n",
      "Metadata Database for file details. The server’s Download Service retrieves metadata from the Metadata\n",
      "Database. Metadata includes information such as file name, size, owner, and access permissions.\n",
      "\n",
      "4. Low-Level Design(LLD) of Dropbox System Design\n",
      "A lot of people assume designing a Dropbox is that all they just need to do is to use some cloud services,\n",
      "upload the file, and download the file whenever they want but that’s not how it works. The core problem is\n",
      "“Where and how to save the files? “. Suppose you want to share a file that can be of any size (small or\n",
      "big) and you upload it into the cloud.»\n",
      "\n",
      "Question: Is there any mention of adopting serverless cloud services to optimize resource usage?\n",
      "\n",
      "Reasoning: Let's think step by step in order to Answer: No --- Context: [1] «7. Scalabilty for Dropbox System Design Horizontal Scaling We can add more servers behind the load balancer to increase the capacity of each service. This is known as Horizontal Scaling and each service can be independently scaled horizontally in our design. Database Sharding Metadata DB is sharded based on object_id. Our hash function will map each object_id to a random server where we can store the file/folder metadata. To query for a particular object_id, service can determine the database server using same hash function and query for data. This approach will distribute our database load\n",
      "\n",
      "Answer:\u001b[32m No\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Give a concrete yes or no or not applicable answer to a question based on the retrieved context.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Is there any mention of scaling down applications during idle periods to minimize resource usage?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of removing unused assets to optimize performance?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of minimizing the total number of deployed environments to save resources?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of scaling down Kubernetes applications when not in use to reduce resource usage?\n",
      "Answer: Not Applicable\n",
      "\n",
      "Question: Is there any mention of optimizing storage utilization to reduce energy consumption?\n",
      "Answer: Yes\n",
      "\n",
      "Question: Is there any mention of optimizing average CPU utilization to ensure efficient use of resources?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of managing peak CPU utilization to avoid over-provisioning?\n",
      "Answer: No\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: Output nothing else apart from either yes, no, or not applicable.\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «-----\n",
      "\n",
      "4.3. Message Queuing Service\n",
      "The messaging service queue will be responsible for the asynchronous communication between the\n",
      "clients and the synchronization service.\n",
      "\n",
      "design-dropbox-4\n",
      "\n",
      "Below are the main requirements of the Message Queuing Service.\n",
      "\n",
      "Ability to handle lots of reading and writing requests.\n",
      "Store lots of messages in a highly available and reliable queue.\n",
      "High performance and high scalability.\n",
      "Provides load balancing and elasticity for multiple instances of the Synchronization Service.\n",
      "There will be two types of messaging queues in the service.»\n",
      "[2] «Request Queue:\n",
      "This will be a global request queue shared among all the clients.\n",
      "Whenever a client receives any update or changes in the files/folder it sends the request through the\n",
      "request queue.\n",
      "This request is received by the synchronization service to update the metadata database.\n",
      "Response Queue:\n",
      "There will be an individual response queue corresponding to the individual clients.\n",
      "The synchronization service broadcast the update through this response queue and this response queue\n",
      "will deliver the updated messages to each client and then these clients will update their respective files\n",
      "accordingly.\n",
      "The message will never be lost even if the client will be disconnected from the internet (the benefit of\n",
      "using the messaging queue service).»\n",
      "[3] «7. Scalabilty for Dropbox System Design\n",
      "Horizontal Scaling\n",
      "We can add more servers behind the load balancer to increase the capacity of each service. This is\n",
      "known as Horizontal Scaling and each service can be independently scaled horizontally in our design.\n",
      "Database Sharding\n",
      "Metadata DB is sharded based on object_id. Our hash function will map each object_id to a random\n",
      "server where we can store the file/folder metadata. To query for a particular object_id, service can\n",
      "determine the database server using same hash function and query for data. This approach will distribute\n",
      "our database load to multiple servers making it scalable.\n",
      "Cache Sharding\n",
      "Similar to Metadata DB Sharding, we are distributing the cache to multiple servers. In-fact Redis has out»\n",
      "\n",
      "Question: Is there any mention of queuing non-urgent processing requests to reduce peak loads?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m Answer: No\n",
      "\n",
      "Reasoning: The context provided discusses the design and requirements for a messaging service, including request and response queues. However, there is no mention of queuing non-urgent processing requests specifically to reduce peak loads within this text. Therefore, based on the given information, we can conclude that such practices are not mentioned or implied in the context provided.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Give a concrete yes or no or not applicable answer to a question based on the retrieved context.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Is there any mention of scaling down applications during idle periods to minimize resource usage?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of removing unused assets to optimize performance?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of minimizing the total number of deployed environments to save resources?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of scaling down Kubernetes applications when not in use to reduce resource usage?\n",
      "Answer: Not Applicable\n",
      "\n",
      "Question: Is there any mention of optimizing storage utilization to reduce energy consumption?\n",
      "Answer: Yes\n",
      "\n",
      "Question: Is there any mention of optimizing average CPU utilization to ensure efficient use of resources?\n",
      "Answer: No\n",
      "\n",
      "Question: Is there any mention of managing peak CPU utilization to avoid over-provisioning?\n",
      "Answer: No\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: Output nothing else apart from either yes, no, or not applicable.\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «-----\n",
      "\n",
      "4.3. Message Queuing Service\n",
      "The messaging service queue will be responsible for the asynchronous communication between the\n",
      "clients and the synchronization service.\n",
      "\n",
      "design-dropbox-4\n",
      "\n",
      "Below are the main requirements of the Message Queuing Service.\n",
      "\n",
      "Ability to handle lots of reading and writing requests.\n",
      "Store lots of messages in a highly available and reliable queue.\n",
      "High performance and high scalability.\n",
      "Provides load balancing and elasticity for multiple instances of the Synchronization Service.\n",
      "There will be two types of messaging queues in the service.»\n",
      "[2] «Request Queue:\n",
      "This will be a global request queue shared among all the clients.\n",
      "Whenever a client receives any update or changes in the files/folder it sends the request through the\n",
      "request queue.\n",
      "This request is received by the synchronization service to update the metadata database.\n",
      "Response Queue:\n",
      "There will be an individual response queue corresponding to the individual clients.\n",
      "The synchronization service broadcast the update through this response queue and this response queue\n",
      "will deliver the updated messages to each client and then these clients will update their respective files\n",
      "accordingly.\n",
      "The message will never be lost even if the client will be disconnected from the internet (the benefit of\n",
      "using the messaging queue service).»\n",
      "[3] «7. Scalabilty for Dropbox System Design\n",
      "Horizontal Scaling\n",
      "We can add more servers behind the load balancer to increase the capacity of each service. This is\n",
      "known as Horizontal Scaling and each service can be independently scaled horizontally in our design.\n",
      "Database Sharding\n",
      "Metadata DB is sharded based on object_id. Our hash function will map each object_id to a random\n",
      "server where we can store the file/folder metadata. To query for a particular object_id, service can\n",
      "determine the database server using same hash function and query for data. This approach will distribute\n",
      "our database load to multiple servers making it scalable.\n",
      "Cache Sharding\n",
      "Similar to Metadata DB Sharding, we are distributing the cache to multiple servers. In-fact Redis has out»\n",
      "\n",
      "Question: Is there any mention of queuing non-urgent processing requests to reduce peak loads?\n",
      "\n",
      "Reasoning: Let's think step by step in order to Answer: No Reasoning: The context provided discusses the design and requirements for a messaging service, including request and response queues. However, there is no mention of queuing non-urgent processing requests specifically to reduce peak loads within this text. Therefore, based on the given information, we can conclude that such practices are not mentioned or implied in the context provided.\n",
      "\n",
      "Answer:\u001b[32m No\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(lm.inspect_history(n=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e49b951-4c58-41ef-a339-0913cbc6e28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 7  (57.1): 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [02:55<00:00, 25.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 7  (57.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/thuva_siva29/green-software-foundation/.venv/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:266: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['False' 'False' '✔️ [True]' '✔️ [True]' '✔️ [True]']' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8c13b th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8c13b td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8c13b_row0_col0, #T_8c13b_row0_col1, #T_8c13b_row0_col2, #T_8c13b_row0_col3, #T_8c13b_row0_col4, #T_8c13b_row1_col0, #T_8c13b_row1_col1, #T_8c13b_row1_col2, #T_8c13b_row1_col3, #T_8c13b_row1_col4, #T_8c13b_row2_col0, #T_8c13b_row2_col1, #T_8c13b_row2_col2, #T_8c13b_row2_col3, #T_8c13b_row2_col4, #T_8c13b_row3_col0, #T_8c13b_row3_col1, #T_8c13b_row3_col2, #T_8c13b_row3_col3, #T_8c13b_row3_col4, #T_8c13b_row4_col0, #T_8c13b_row4_col1, #T_8c13b_row4_col2, #T_8c13b_row4_col3, #T_8c13b_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8c13b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8c13b_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_8c13b_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_8c13b_level0_col2\" class=\"col_heading level0 col2\" >context</th>\n",
       "      <th id=\"T_8c13b_level0_col3\" class=\"col_heading level0 col3\" >pred_answer</th>\n",
       "      <th id=\"T_8c13b_level0_col4\" class=\"col_heading level0 col4\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8c13b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8c13b_row0_col0\" class=\"data row0 col0\" >Is there any mention of reducing transmitted data to save energy?</td>\n",
       "      <td id=\"T_8c13b_row0_col1\" class=\"data row0 col1\" >Yes</td>\n",
       "      <td id=\"T_8c13b_row0_col2\" class=\"data row0 col2\" >['The synchronization service receives the request from the request queue of the messaging services and\\nupdates the metadata database with the latest changes.\\nAlso, the synchronization service...</td>\n",
       "      <td id=\"T_8c13b_row0_col3\" class=\"data row0 col3\" >No</td>\n",
       "      <td id=\"T_8c13b_row0_col4\" class=\"data row0 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c13b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8c13b_row1_col0\" class=\"data row1 col0\" >Is there any mention of allowing independent scaling of logical components?</td>\n",
       "      <td id=\"T_8c13b_row1_col1\" class=\"data row1 col1\" >Yes</td>\n",
       "      <td id=\"T_8c13b_row1_col2\" class=\"data row1 col2\" >['Scaling can be achieved using techniques such as vertical scaling (increasing hardware capabilities) or\\nhorizontal scaling (adding more machines).\\nHowever, horizontal scaling for relational databases often involves...</td>\n",
       "      <td id=\"T_8c13b_row1_col3\" class=\"data row1 col3\" >No</td>\n",
       "      <td id=\"T_8c13b_row1_col4\" class=\"data row1 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c13b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8c13b_row2_col0\" class=\"data row2 col0\" >Is there any mention of using relevant metrics to dynamically adjust Kubernetes workloads?</td>\n",
       "      <td id=\"T_8c13b_row2_col1\" class=\"data row2 col1\" >Not Applicable</td>\n",
       "      <td id=\"T_8c13b_row2_col2\" class=\"data row2 col2\" >['7. Scalabilty for Dropbox System Design\\nHorizontal Scaling\\nWe can add more servers behind the load balancer to increase the capacity of each service. This is\\nknown as...</td>\n",
       "      <td id=\"T_8c13b_row2_col3\" class=\"data row2 col3\" >Not applicable</td>\n",
       "      <td id=\"T_8c13b_row2_col4\" class=\"data row2 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c13b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8c13b_row3_col0\" class=\"data row3 col0\" >Is there any mention of scaling infrastructure based on real-time user demand?</td>\n",
       "      <td id=\"T_8c13b_row3_col1\" class=\"data row3 col1\" >No</td>\n",
       "      <td id=\"T_8c13b_row3_col2\" class=\"data row3 col2\" >['7. Scalabilty for Dropbox System Design\\nHorizontal Scaling\\nWe can add more servers behind the load balancer to increase the capacity of each service. This is\\nknown as...</td>\n",
       "      <td id=\"T_8c13b_row3_col3\" class=\"data row3 col3\" >No</td>\n",
       "      <td id=\"T_8c13b_row3_col4\" class=\"data row3 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8c13b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8c13b_row4_col0\" class=\"data row4 col0\" >Is there any mention of setting storage retention policies to automatically clean up old data?</td>\n",
       "      <td id=\"T_8c13b_row4_col1\" class=\"data row4 col1\" >No</td>\n",
       "      <td id=\"T_8c13b_row4_col2\" class=\"data row4 col2\" >['request. We generally mention availability as 5 Nine’s, 4 Nine’s, etc. 5 Nine’s means 99.999% availability,\\n4 Nine means 99.99% availability, and so on.\\nDurability: Durability means...</td>\n",
       "      <td id=\"T_8c13b_row4_col3\" class=\"data row4 col3\" >No</td>\n",
       "      <td id=\"T_8c13b_row4_col4\" class=\"data row4 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f3e02a4b810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 2 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "57.14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = dspy.evaluate.answer_exact_match\n",
    "evaluate_on_dataset(RAG(), metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9aaffb6b-406d-40b8-aa96-ac5284583998",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_rag.save(\"file.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
