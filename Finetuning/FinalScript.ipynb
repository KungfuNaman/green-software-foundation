{"cells":[{"cell_type":"markdown","source":["## Run this on T4 GPU on Google Colab"],"metadata":{"id":"Lu6j3Z9Sl1tL"}},{"cell_type":"markdown","source":["## Steps:\n","[Model prep](#Model) <br>\n","[Data prep](#Data) <br>\n","[Train](#Train) <br>\n","[Run the model](#Inference) <br>\n","[Save the model](#Save) <br>\n","<br>\n","\n","Unsloth Github: [here](https://github.com/unslothai/unsloth#installation-instructions---conda).\n","\n","Sample Dataset: [Open Assistant dataset](https://huggingface.co/datasets/philschmid/guanaco-sharegpt-style) in ShareGPT style."],"metadata":{"id":"-adm3SXPmIxE"}},{"cell_type":"markdown","source":["<a name=\"Model\"></a>\n","## <font color=green>**Model Prep**</font>"],"metadata":{"id":"NLwD_fSnn6M-"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"2eSvM9zX_2d3","executionInfo":{"status":"ok","timestamp":1721227953885,"user_tz":-60,"elapsed":36087,"user":{"displayName":"capsule604","userId":"07523244262261437843"}}},"outputs":[],"source":["# hide output\n","%%capture\n","\n","# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"rfO8_Rtmfn5x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721227955512,"user_tz":-60,"elapsed":1655,"user":{"displayName":"capsule604","userId":"07523244262261437843"}},"outputId":"548f2740-90e7-40fb-8b8b-f3f36ceeb5a9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### Import the model\n","* We support Llama, Mistral, Phi-3, Gemma, Yi, DeepSeek, Qwen, TinyLlama, Vicuna, Open Hermes etc\n","* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n","* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n","* With [PR 26037](https://github.com/huggingface/transformers/pull/26037), we support downloading 4bit models **4x faster**! [Our repo](https://huggingface.co/unsloth) has Llama, Mistral 4bit models.\n","* [**NEW**] We make Llama-3 15 trillion tokens **2x faster**! See our [Llama-3 notebook](https://colab.research.google.com/drive/135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp?usp=sharing)"],"metadata":{"id":"r2v_X2fA0Df5"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"QmUBVEnvCDJv","colab":{"base_uri":"https://localhost:8080/","height":362,"referenced_widgets":["ecb54928de454e3cb166451759df621d","7cada174322648d0b832733603f7d3f3","e67e6001750e4f32969b78e337ff5c35","1b4757bf17d24eb480bb55c815099cc4","e8aa434a61eb4f3e86a86f583075e848","58e3de1a35ed47b689b9c02378b3907f","c297dd752f6b4e9a8d684dea18bcdfc9","0ba1362eddb64d92be61bbd4b522d4c0","5c788a9fd01d400abfb6c1c207d85b71","5ab384c0619e48a69ce45ffb9b64feea","75938c714aef4e56a0669d44ed45c86e","cfc3398b12944e8ca45de77fee3f8bde","6ab0a576acc54a52b41edf3dd527e0c2","832c38cba77a4424be0683a755e63752","a0b24efc14274f1ca826907035cda1f8","a90eeb14c4924a699fba6fb76c213028","cd4c84b9a73c4a8b82173710d8e2bf18","07eb6953fc694818ad97fe805758ff69","875dd8bf08ff4b769ebd37ca2ee005c6","98abd4f283eb4a71bba380731d02e2ab","c9d10a5ab5974eb29347885fb0fcde50","578f51ffd0b24c4abea968d9058df70e","f59d7c394546416f8e3a8fed76ee8b23","06189c45a0684162843f6baca0890775","6d938d0e190a49abb96d1038a9cfe62f","421853b4212a488396968b09df1750a0","5ad40417128349c594d11fee87643dc4","88f7ff57c4ab42538d15627b75accdbc","0c95d325e98e4312953f50e05b99f114","f303c47417da4177a8baab05646ab922","b78888d264b047a5a0a9dea5847f709b","615a32743d1b47de8f62dc373a15868c","0475d91e16f141088fa21fb5a6c253b8","b2a08cc8a4f148d3a8e90c9f8dfbcc6d","7e72e6bce06c400fb4a0eb38b192b14e","49b6050493264265a4f8cffba3986611","a524478330c14a2d84eaab4df24d5da7","5fba2ae116cf4704ab42eac48eddf42d","0c80b40ef2ca4c7aa70f148b05d4a5de","25c3aaa1197f44b9bf2fd9a7f8ca9b13","6213b6426a244d0396176ef6567e47a7","52ce5b84963a4f6da02e229a445485e6","321ecf9ad90649aab410d6db0a88d198","45ed1bab2fda4b8b87a8a8864f64025f","9ce7b66676744bceb179e7a1f84c147d","6cc1542b6f284cc9be2aba908789907d","2705ef50e16142d4b583ec7ec3fd334b","a907d7d6f7804ce8acf2d817270d713a","5d22fd7b8b2445bd8c217a81d1d35ed9","fd4b8747d3e947acbfe1f525ed37b63c","b52529c214bb4e868f5903a572a18586","2af1903c0f5d437f9ffa45c38e8a4976","00da24866156472099a57b21f8c2d4a2","0874e760feac4cbe98ae01373cdac836","2abb0244377448d5b5ad1262b283d194","b52e96f245d541af91fbc390b4734dcc","a420153017c54469bf62ae021b72b1c8","3250ab192f2a4aef8188f411a8c0ba58","786a2b507e5647ffa1e2be719d66b48d","7cac5229850a49f0a4e3f0089c509eae","5bb8d5c0c668443a9763c8290b789249","f92463dfa95a404f84bde240673efab0","21c571f0150646aaa38bc2f31ffa1fc5","b63b65eac5e541ad9269069cb0b3f905","e5784fe1769b44718ba6b2a1e3171961","3bcae41373ff4474a475287366dd4d9e","4191994160274dfd83794ce3326d63e5","7a4420b571a44d82aac1b0a85d9cc04a","7d1cfb105a5847ab9102d02c8ef8c6f3","b2c38dfd9fa145d58193eb15c1958ca2","b82994f24ab6426490e8c89f10eb9865","c0bcf3f98ddf451583391a6dbca48b47","cfdc342fcf6e4cafa6fd75fae9bc4173","9007b297d26346d196898b42f627f4b2","b65a029c795f44b48098866776f393e7","1f3eb6b6bb734a76980ac6cdc5fb848b","b6deb20d34794fc7b6e27f1f212455e9","4c437d763b844a548899160de10ba83c","c927ddda9ebc497e8dedcad23862a933","bc9dfbd2f5614e59871f4b35a36f8593","c3206c6fec394afbb0ab16f9fcba0336","4155549030cf431284b59534f48e3e03","682a25bf44104cb4b2325a06884ae72b","6bb0a8d8077542288cd1c704ca5f8a43","5050229144c74ad3987ab464e0efa55e","025261c18b3d41d880e3b68646f6436e","774c6fcb33554f35ba2100401b362e92","dd8fda5b550f417db9599618bc3ccc81"]},"executionInfo":{"status":"ok","timestamp":1721228055117,"user_tz":-60,"elapsed":30211,"user":{"displayName":"capsule604","userId":"07523244262261437843"}},"outputId":"1d39efdd-c288-415e-9fa3-e4785c943e0b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecb54928de454e3cb166451759df621d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth: Fast Mistral patching release 2024.7\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.26.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/2.26G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfc3398b12944e8ca45de77fee3f8bde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/145 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f59d7c394546416f8e3a8fed76ee8b23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2a08cc8a4f148d3a8e90c9f8dfbcc6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ce7b66676744bceb179e7a1f84c147d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b52e96f245d541af91fbc390b4734dcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4191994160274dfd83794ce3326d63e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c437d763b844a548899160de10ba83c"}},"metadata":{}}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048    # Token length model can proecess - Choose any! We auto support RoPE Scaling internally!\n","dtype = None        # Numerial accuracy when calculation - None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True     # Save memory space - Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/mistral-7b-v0.3-bnb-4bit\",         # New Mistral v3 2x faster!\n","    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n","    \"unsloth/llama-3-8b-bnb-4bit\",            # Llama-3 15 trillion tokens model 2x faster!\n","    \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n","    \"unsloth/llama-3-70b-bnb-4bit\",\n","    \"unsloth/Phi-3-mini-4k-instruct\",          # Phi-3 2x faster!\n","    \"unsloth/Phi-3-medium-4k-instruct\",\n","    \"unsloth/mistral-7b-bnb-4bit\",\n","    \"unsloth/gemma-7b-bnb-4bit\",             # Gemma 2.2x faster!\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"microsoft/Phi-3-mini-4k-instruct\",   # Change base model here\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\",                # hugging-face token (if using gated models like meta-llama/Llama-2-7b-hf)\n",")"]},{"cell_type":"markdown","source":["### Use LoRA Optimization & Accelaration\n","We now add LoRA adapters so we only need to update 1 to 10% of all parameters!\n","<br>\n","\n","LoRA (Low-Rank Adaptation)<br>\n","Reduces memory footprint and computation requirements\n","* model = The chosen model\n","* r = The rank of low-rank model. Any number > 0 (8,16,32,64,128). Bigger r = More calc cost & Higher accuracy\n","* target_modules = Modules need LoRA to calculate\n","* lora_alpha = To scale the output of low-rank matrix. Will be multiplied with the final matrix output scale\n","* lora_dropout = Rate of DropOut Layer(layer preventing over-fitting)\n","* bias = If use bias terms in low-rank matrix factorization\n","* use_gradient_checkpointing = For reducing the memory consumption\n","* random_state = Seed\n","* use_rslora = Rank stabilized LoRA (augmented verison of LoRA)\n","* loftq_config = For futher quantification and compression"],"metadata":{"id":"SXd9bTZd1aaL"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"6bZsfBuZDeCL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721228067059,"user_tz":-60,"elapsed":4627,"user":{"displayName":"capsule604","userId":"07523244262261437843"}},"outputId":"243b4c5d-9e52-4b2e-86a7-96a63cc4651b"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}],"source":["from unsloth import FastLanguageModel\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0,  # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"markdown","source":["<a name=\"Data\"></a>\n","## <font color=green>**Data Prep**</font>\n","We now use the `Phi-3` format for conversation style finetunes. We use [Open Assistant conversations](https://huggingface.co/datasets/philschmid/guanaco-sharegpt-style) in ShareGPT style. Phi-3 renders multi turn conversations like below:\n","\n","```\n","<s><|user|>\n","Hi!<|end|>\n","<|assistant|>\n","Hello! How are you?<|end|>\n","<|user|>\n","I'm doing great! And you?<|end|>\n","\n","```\n","\n","**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n","\n","We use our `get_chat_template` function to get the correct chat template. We support `zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old` and our own optimized `unsloth` template.\n","\n","Note ShareGPT uses `{\"from\": \"human\", \"value\" : \"Hi\"}` and not `{\"role\": \"user\", \"content\" : \"Hi\"}`, so we use `mapping` to map it.\n","\n","For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."],"metadata":{"id":"vITh0KVJ10qX"}},{"cell_type":"markdown","source":["**Aligning DIY Dataset to Standard Format<br>**\n","\n","format reference: [philschmid/guanaco-sharegpt-style](https://huggingface.co/datasets/philschmid/guanaco-sharegpt-style)"],"metadata":{"id":"C6Hp8EnQhXs_"}},{"cell_type":"code","source":["from datasets import Dataset\n","from datasets import load_dataset\n","import json\n","\n","# Change to your training set path\n","TRAINING_SET_PATH = \"/content/ds.json\"\n","RAW_TRAINING_SET_PATH = \"/content/drive/MyDrive/SSE Group Project - Green Foundation/Training Set/combined_trainingset.json\"\n","\n","# # load dataset in dictionary\n","# dataset = load_dataset(\"json\", data_files=TRAINING_SET_PATH, split = \"train\")\n","# dataset = dataset.to_dict()\n","# print(\"The dataset's type changed to: \", type(dataset))\n","\n","# # get the queries list\n","# queries_lst = dataset[\"queries\"][0]\n","\n","# Load json file\n","with open(RAW_TRAINING_SET_PATH, 'r', encoding='utf-8') as f:\n","    raw_trainingset = json.load(f)\n","\n","# Get queires list\n","def get_all_data_to_lst(combined_dict):\n","  res = []\n","  for i,q_lst in combined_dict.items():\n","    for j in q_lst:\n","      res.append(j)\n","  return res\n","queries_lst = get_all_data_to_lst(raw_trainingset)\n","print(queries_lst[0])"],"metadata":{"id":"hggqeSMw63KT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721228068504,"user_tz":-60,"elapsed":1447,"user":{"displayName":"capsule604","userId":"07523244262261437843"}},"outputId":"2ef8727d-ff49-49d0-e3f6-65f5589dd1a8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["{'query': 'Does the application/framework use content delivery networks (CDNs) to minimize recomputation or fetching of static data?', 'context': 'Our web platform serves static assets such as images, CSS, and JavaScript files using a network of global CDNs to ensure fast delivery to users around the world.', 'explanation': 'The platform uses CDNs to deliver static assets globally, reducing load times and server strain, which aligns with the green practice.', 'judgement': 'Yes'}\n"]}]},{"cell_type":"code","source":["# Format the queries list\n","formatted_queries = []\n","for qa_dict in queries_lst:\n","  formatted_queries.append([])\n","  formatted_queries[-1].append( {\n","      \"from\": \"human\",\n","      \"value\": \"Using this as context '{context}', Answer this question: '{query}'\".format( context=qa_dict[\"context\"], query=qa_dict[\"query\"])\n","      } )\n","  formatted_queries[-1].append( {\n","      \"from\": \"gpt\",\n","      \"value\": \"Judgement: {judge}, Explanation: {exp}\".format( judge=qa_dict[\"judgement\"], exp=qa_dict[\"explanation\"])\n","      } )\n","\n","\n","print(\"There are \", len(formatted_queries), \" QA queries in training set.\")\n","print(\"Current structure of each QA query: \\n\", formatted_queries[0])\n","\n","# Convert dict back to Dataset type\n","processed_dataset = {\"conversations\": formatted_queries}\n","dataset = Dataset.from_dict(processed_dataset)\n","print(\"The dataset's type now: \", type(dataset))"],"metadata":{"id":"y0H8u4CR65Lk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721228068504,"user_tz":-60,"elapsed":5,"user":{"displayName":"capsule604","userId":"07523244262261437843"}},"outputId":"406fb330-9196-47b1-db46-d10e7347a71b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["There are  1558  QA queries in training set.\n","Current structure of each QA query: \n"," [{'from': 'human', 'value': \"Using this as context 'Our web platform serves static assets such as images, CSS, and JavaScript files using a network of global CDNs to ensure fast delivery to users around the world.', Answer this question: 'Does the application/framework use content delivery networks (CDNs) to minimize recomputation or fetching of static data?'\"}, {'from': 'gpt', 'value': 'Judgement: Yes, Explanation: The platform uses CDNs to deliver static assets globally, reducing load times and server strain, which aligns with the green practice.'}]\n","The dataset's type now:  <class 'datasets.arrow_dataset.Dataset'>\n"]}]},{"cell_type":"code","source":["from unsloth.chat_templates import get_chat_template\n","\n","tokenizer = get_chat_template(\n","    tokenizer,\n","    chat_template = \"phi-3\", # Supports zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, unsloth\n","    mapping = {\"role\" : \"from\", \"content\" : \"value\", \"user\" : \"human\", \"assistant\" : \"gpt\"}, # ShareGPT style\n",")\n","\n","def formatting_prompts_func(examples):\n","    convos = examples[\"conversations\"]\n","    texts = []\n","    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n","    return { \"text\" : texts, }\n","\n","\n","dataset = dataset.map(formatting_prompts_func, batched = True,)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["8151caecef784930accc862a9ee80c03","9de35da4ae194ee7838707bbf6d635db","d60447c9b2a241a3a7d0186a92b6e42b","b125392e1953429597c77337b7336875","d7c64f3c502a4d6d992fc7201a0248ce","f697013eb6174007ac8aed6e84777370","9a4fd5dbec0b4554a4ee024a463c9f66","54b610ddee504ba7a86abed639076ed5","0e6bd23b13b342f6afdc9867999bcf24","b4c4a63025cf48a38cf324803d28d31a","6fc2568e20d94f92a3011b1ff11dadb9"]},"id":"Edrn7Rxmojtu","outputId":"b79f5795-18a4-40a2-a14d-675cc9f777db","executionInfo":{"status":"ok","timestamp":1721228068794,"user_tz":-60,"elapsed":294,"user":{"displayName":"capsule604","userId":"07523244262261437843"}}},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1558 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8151caecef784930accc862a9ee80c03"}},"metadata":{}}]},{"cell_type":"markdown","source":["**Sample structure of database**"],"metadata":{"id":"yrxzv8PHli-x"}},{"cell_type":"code","source":["idx = 5\n","print(\"Type: \", type(dataset))\n","print()\n","print(\"-- conversation --\")\n","print(dataset[idx]['conversations'])\n","print()\n","print(\"-- text --\")\n","print(dataset[idx]['text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnhGzPOjGnK2","executionInfo":{"status":"ok","timestamp":1721228068794,"user_tz":-60,"elapsed":2,"user":{"displayName":"capsule604","userId":"07523244262261437843"}},"outputId":"7920c027-f282-41a7-8605-4f668fa1900e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Type:  <class 'datasets.arrow_dataset.Dataset'>\n","\n","-- conversation --\n","[{'from': 'human', 'value': \"Using this as context 'Our website does not leverage CDNs and instead relies on the primary server to handle all static content delivery.', Answer this question: 'Does the application/framework use content delivery networks (CDNs) to minimize recomputation or fetching of static data?'\"}, {'from': 'gpt', 'value': 'Judgement: No, Explanation: The reliance on the primary server for all static content delivery suggests that CDNs are not utilized, which can affect performance and scalability.'}]\n","\n","-- text --\n","<s><|user|>\n","Using this as context 'Our website does not leverage CDNs and instead relies on the primary server to handle all static content delivery.', Answer this question: 'Does the application/framework use content delivery networks (CDNs) to minimize recomputation or fetching of static data?'<|end|>\n","<|assistant|>\n","Judgement: No, Explanation: The reliance on the primary server for all static content delivery suggests that CDNs are not utilized, which can affect performance and scalability.<|end|>\n","\n"]}]},{"cell_type":"markdown","source":["<a name=\"Train\"></a>\n","## <font color=green>**Train the model**</font>\n","Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"],"metadata":{"id":"idAEIeSQ3xdS"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"95_Nn-89DhsL","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["969cdc6c53c44106b5dfd04163ebb73b","99ecdb5d66c54e5f815b615b02697c90","5405ea42a23e41dd9776f0d21ad6f30b","bff6bb26648b41e89045c7d4c1f28b2d","41a11f975ed0487b99316f08db7b1f9d","f0ddf583dfa54252aefa245c423ba55b","939db90a05344cdf8e8c2c1cebe416ea","040fc26e217a453b80ac472029c234fa","5e85ad43898c4aee97c51f657b4521fa","4450c45ce67e459d89af5ff7e2cdec8c","eedbc0a783ae499db467f391ceaf35a7"]},"outputId":"536820eb-b76e-43c7-a066-0206c5c9bdcf","executionInfo":{"status":"ok","timestamp":1721228069921,"user_tz":-60,"elapsed":1128,"user":{"displayName":"capsule604","userId":"07523244262261437843"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/1558 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"969cdc6c53c44106b5dfd04163ebb73b"}},"metadata":{}}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        num_train_epochs=10,\n","        #max_steps = 60,\n","        learning_rate = 2e-5,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 10,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"/content/drive/MyDrive/Model_checkpoints\",\n","        save_strategy = \"epoch\"\n","        #save_steps = 388,\n","    ),\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"2ejIt2xSNKKp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a76409ad-84ec-417e-fee3-5cb21c2d0575","executionInfo":{"status":"ok","timestamp":1721228069921,"user_tz":-60,"elapsed":3,"user":{"displayName":"capsule604","userId":"07523244262261437843"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","2.283 GB of memory reserved.\n"]}],"source":["#@title Show current memory stats\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"yqxqAZ7KJ4oL","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"38ef4a0a-593a-40ff-c11f-e70cc15142f5","executionInfo":{"status":"ok","timestamp":1721233115625,"user_tz":-60,"elapsed":3875383,"user":{"displayName":"capsule604","userId":"07523244262261437843"}}},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 1,558 | Num Epochs = 10\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 1,940\n"," \"-____-\"     Number of trainable parameters = 29,884,416\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='443' max='1940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 443/1940 19:16 < 1:05:24, 0.38 it/s, Epoch 2.27/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>2.585300</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.456400</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.205500</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.952200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.661800</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>1.429700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>1.294000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>1.157800</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>1.116400</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.079900</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>1.033200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>1.036300</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.984200</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.975700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.992500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>1.012800</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.935600</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.925100</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.926900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.913100</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.902000</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.902300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.876600</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.874800</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.886900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.890200</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.917500</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.879700</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.898800</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.849700</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.873000</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.874400</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.861400</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.833200</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.840900</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.835400</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.837900</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.847000</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.833000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.800200</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.835000</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.809300</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.822800</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.838300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1940' max='1940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1940/1940 1:23:54, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>2.585300</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.456400</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.205500</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.952200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.661800</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>1.429700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>1.294000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>1.157800</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>1.116400</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.079900</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>1.033200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>1.036300</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.984200</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.975700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.992500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>1.012800</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.935600</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.925100</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.926900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.913100</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.902000</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.902300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.876600</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.874800</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.886900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.890200</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.917500</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.879700</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.898800</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.849700</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.873000</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.874400</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.861400</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.833200</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.840900</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.835400</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.837900</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.847000</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.833000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.800200</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.835000</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.809300</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.822800</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.838300</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.791400</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.786400</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.778500</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.780400</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.761900</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.764400</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.762800</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.777100</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.773800</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.754100</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.781400</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.778300</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.779500</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.742900</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.732400</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.732000</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.730800</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.726700</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.725300</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.715500</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.695200</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.701300</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.733600</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.696500</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.719900</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.710200</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.704400</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.687900</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.686700</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.682300</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.677300</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.693700</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.702500</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.700800</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.666300</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.625400</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.629500</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.630300</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.641700</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.597000</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.666700</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.650100</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.663400</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.635900</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.656200</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.640100</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.646100</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.616000</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.659400</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.615700</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.644100</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.598300</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.648200</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.597700</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.600200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.588100</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.615300</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.608200</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.614100</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.586800</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.576600</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.612300</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.585300</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.566100</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.606000</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.585200</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.577100</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.581900</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.591500</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.591700</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.599100</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.587200</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.592000</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.566600</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.553400</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.608800</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.581600</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.557200</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.555100</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.559100</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.538300</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.561800</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.582100</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.563700</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.561800</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.570700</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.529100</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.571600</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.555300</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.579500</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.527200</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.533400</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.515100</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.550100</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.541600</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.538100</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.542600</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.523900</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.556500</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.554100</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.562100</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.549300</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.515600</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.534000</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.537200</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.537800</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.556600</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.539100</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.535600</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.540700</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.525500</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.510000</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.543600</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.531500</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.513800</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.557200</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.530000</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.517200</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.524900</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.521400</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.520000</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.553400</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.534500</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.539600</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.522500</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.525700</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.509000</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.497700</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.526800</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.519500</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.526800</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.534800</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.485000</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.520100</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.516500</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.525100</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.512000</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.527700</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.510100</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.503400</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.498800</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.527600</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.528300</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.526100</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.515800</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.525400</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.522000</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.504200</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.510700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"pCqnaKmlO1U9","executionInfo":{"status":"ok","timestamp":1721233115636,"user_tz":-60,"elapsed":0,"user":{"displayName":"capsule604","userId":"07523244262261437843"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1485fb04-832b-44e6-f65d-988a062c4774"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["5043.0925 seconds used for training.\n","84.05 minutes used for training.\n","Peak reserved memory = 2.615 GB.\n","Peak reserved memory for training = 0.332 GB.\n","Peak reserved memory % of max memory = 17.731 %.\n","Peak reserved memory for training % of max memory = 2.251 %.\n"]}],"source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"]},{"cell_type":"markdown","source":["<a name=\"Save\"></a>\n","## <font color=green>**Saving, loading finetuned models**</font>\n","To save the final model, use `save_pretrained` for a local save to GGUF.\n"],"metadata":{"id":"uMuVrWbjAzhc"}},{"cell_type":"markdown","source":["### GGUF / llama.cpp Conversion\n","To save to `GGUF`, clone `llama.cpp` and we default save it to `q4_k_m` for best size. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n","\n","Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n","* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n","* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n","* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K."],"metadata":{"id":"TCv4vXHd61i7"}},{"cell_type":"code","source":["# Save to 8bit Q8_0\n","if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n","\n","# Save to 16bit GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n","\n","# Save to q4_k_m GGUF\n","if True: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")"],"metadata":{"id":"FqfebeAdT073","executionInfo":{"status":"ok","timestamp":1721234020722,"user_tz":-60,"elapsed":851095,"user":{"displayName":"capsule604","userId":"07523244262261437843"}},"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3368dfea-78f2-49fa-c54d-bacace09ce92"},"execution_count":20,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n","We shall switch to Pytorch saving, which will take 3 minutes and not 30 minutes.\n","To force `safe_serialization`, set it to `None` instead.\n","Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n","model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n","Unsloth: Will remove a cached repo with size 2.3G\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Unsloth: Merging 4bit and LoRA weights to 16bit...\n","Unsloth: Will use up to 7.45 out of 12.67 RAM for saving.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 32/32 [00:02<00:00, 12.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Saving tokenizer... Done.\n","Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n","Unsloth: Saving model/pytorch_model-00001-of-00002.bin...\n","Unsloth: Saving model/pytorch_model-00002-of-00002.bin...\n","Done.\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Converting mistral model. Can use fast conversion = True.\n"]},{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n","   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n","O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n","\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] will take 10 minutes each.\n"," \"-____-\"     In total, you will have to wait at least 16 minutes.\n","\n","Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Extending model/tokenizer.model with added_tokens.json.\n","Originally tokenizer.model is of size (32000).\n","But we need to extend to sentencepiece vocab size (32011).\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: [1] Converting model at model into f16 GGUF format.\n","The output location will be ./model/unsloth.F16.gguf\n","This will take 3 minutes...\n","INFO:hf-to-gguf:Loading model: model\n","INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n","INFO:hf-to-gguf:Set model parameters\n","INFO:hf-to-gguf:gguf: context length = 4096\n","INFO:hf-to-gguf:gguf: embedding length = 3072\n","INFO:hf-to-gguf:gguf: feed forward length = 8192\n","INFO:hf-to-gguf:gguf: head count = 32\n","INFO:hf-to-gguf:gguf: key-value head count = 32\n","INFO:hf-to-gguf:gguf: rope theta = 10000.0\n","INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n","INFO:hf-to-gguf:gguf: file type = 1\n","INFO:hf-to-gguf:Set model tokenizer\n","INFO:gguf.vocab:Setting special token type bos to 1\n","INFO:gguf.vocab:Setting special token type eos to 32000\n","INFO:gguf.vocab:Setting special token type unk to 0\n","INFO:gguf.vocab:Setting special token type pad to 32009\n","INFO:gguf.vocab:Setting add_bos_token to False\n","INFO:gguf.vocab:Setting add_eos_token to False\n","INFO:gguf.vocab:Setting chat_template to {{ bos_token }}{% for message in messages %}{% if message['from'] == 'human' %}{{'<|user|>\n","' + message['value'] + '<|end|>\n","'}}{% elif message['from'] == 'gpt' %}{{'<|assistant|>\n","' + message['value'] + '<|end|>\n","'}}{% else %}{{'<|' + message['from'] + '|>\n","' + message['value'] + '<|end|>\n","'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\n","' }}{% endif %}\n","INFO:hf-to-gguf:Exporting model...\n","INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00002.bin'\n","INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {3072, 32064}\n","INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00002.bin'\n","INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n","INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n","INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n","INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {3072}\n","INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {3072, 32064}\n","INFO:gguf.gguf_writer:Writing the following files:\n","INFO:gguf.gguf_writer:model/unsloth.F16.gguf: n_tensors = 291, total_size = 7.6G\n","Writing: 100%|██████████| 7.64G/7.64G [01:31<00:00, 83.7Mbyte/s]\n","INFO:hf-to-gguf:Model successfully exported to model/unsloth.F16.gguf\n","Unsloth: Conversion completed! Output location: ./model/unsloth.F16.gguf\n","Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n","main: build = 3409 (30f80ca0)\n","main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n","main: quantizing './model/unsloth.F16.gguf' to './model/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n","llama_model_loader: loaded meta data with 28 key-value pairs and 291 tensors from ./model/unsloth.F16.gguf (version GGUF V3 (latest))\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.type str              = model\n","llama_model_loader: - kv   2:                               general.name str              = model\n","llama_model_loader: - kv   3:                          llama.block_count u32              = 32\n","llama_model_loader: - kv   4:                       llama.context_length u32              = 4096\n","llama_model_loader: - kv   5:                     llama.embedding_length u32              = 3072\n","llama_model_loader: - kv   6:                  llama.feed_forward_length u32              = 8192\n","llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n","llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n","llama_model_loader: - kv   9:                       llama.rope.freq_base f32              = 10000.000000\n","llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n","llama_model_loader: - kv  11:                          general.file_type u32              = 1\n","llama_model_loader: - kv  12:                           llama.vocab_size u32              = 32064\n","llama_model_loader: - kv  13:                 llama.rope.dimension_count u32              = 96\n","llama_model_loader: - kv  14:            tokenizer.ggml.add_space_prefix bool             = false\n","llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = llama\n","llama_model_loader: - kv  16:                         tokenizer.ggml.pre str              = default\n","llama_model_loader: - kv  17:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n","llama_model_loader: - kv  18:                      tokenizer.ggml.scores arr[f32,32064]   = [-1000.000000, -1000.000000, -1000.00...\n","llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,32064]   = [3, 3, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n","llama_model_loader: - kv  20:                tokenizer.ggml.bos_token_id u32              = 1\n","llama_model_loader: - kv  21:                tokenizer.ggml.eos_token_id u32              = 32000\n","llama_model_loader: - kv  22:            tokenizer.ggml.unknown_token_id u32              = 0\n","llama_model_loader: - kv  23:            tokenizer.ggml.padding_token_id u32              = 32009\n","llama_model_loader: - kv  24:               tokenizer.ggml.add_bos_token bool             = false\n","llama_model_loader: - kv  25:               tokenizer.ggml.add_eos_token bool             = false\n","llama_model_loader: - kv  26:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n","llama_model_loader: - kv  27:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:   65 tensors\n","llama_model_loader: - type  f16:  226 tensors\n","[   1/ 291]                    token_embd.weight - [ 3072, 32064,     1,     1], type =    f16, converting to q4_K .. size =   187.88 MiB ->    52.84 MiB\n","[   2/ 291]                  blk.0.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[   3/ 291]                  blk.0.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[   4/ 291]                  blk.0.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[   5/ 291]             blk.0.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[   6/ 291]                blk.0.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[   7/ 291]                  blk.0.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[   8/ 291]                blk.0.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[   9/ 291]               blk.0.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  10/ 291]                blk.0.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  11/ 291]                  blk.1.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  12/ 291]                  blk.1.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  13/ 291]                  blk.1.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[  14/ 291]             blk.1.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  15/ 291]                blk.1.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  16/ 291]                  blk.1.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  17/ 291]                blk.1.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[  18/ 291]               blk.1.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  19/ 291]                blk.1.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  20/ 291]                  blk.2.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  21/ 291]                  blk.2.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  22/ 291]                  blk.2.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[  23/ 291]             blk.2.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  24/ 291]                blk.2.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  25/ 291]                  blk.2.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  26/ 291]                blk.2.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[  27/ 291]               blk.2.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  28/ 291]                blk.2.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  29/ 291]                  blk.3.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  30/ 291]                  blk.3.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  31/ 291]                  blk.3.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[  32/ 291]             blk.3.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  33/ 291]                blk.3.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  34/ 291]                  blk.3.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  35/ 291]                blk.3.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[  36/ 291]               blk.3.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  37/ 291]                blk.3.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  38/ 291]                  blk.4.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  39/ 291]                  blk.4.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  40/ 291]                  blk.4.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  41/ 291]             blk.4.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  42/ 291]                blk.4.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  43/ 291]                  blk.4.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  44/ 291]                blk.4.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  45/ 291]               blk.4.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  46/ 291]                blk.4.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  47/ 291]                  blk.5.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  48/ 291]                  blk.5.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  49/ 291]                  blk.5.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  50/ 291]             blk.5.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  51/ 291]                blk.5.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  52/ 291]                  blk.5.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  53/ 291]                blk.5.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  54/ 291]               blk.5.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  55/ 291]                blk.5.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  56/ 291]                  blk.6.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  57/ 291]                  blk.6.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  58/ 291]                  blk.6.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[  59/ 291]             blk.6.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  60/ 291]                blk.6.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  61/ 291]                  blk.6.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  62/ 291]                blk.6.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[  63/ 291]               blk.6.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  64/ 291]                blk.6.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  65/ 291]                  blk.7.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  66/ 291]                  blk.7.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  67/ 291]                  blk.7.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  68/ 291]             blk.7.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  69/ 291]                blk.7.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  70/ 291]                  blk.7.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  71/ 291]                blk.7.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  72/ 291]               blk.7.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  73/ 291]                blk.7.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  74/ 291]                  blk.8.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  75/ 291]                  blk.8.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  76/ 291]                  blk.8.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  77/ 291]             blk.8.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  78/ 291]                blk.8.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  79/ 291]                  blk.8.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  80/ 291]                blk.8.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  81/ 291]               blk.8.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  82/ 291]                blk.8.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  83/ 291]                  blk.9.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  84/ 291]                  blk.9.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  85/ 291]                  blk.9.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[  86/ 291]             blk.9.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  87/ 291]                blk.9.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  88/ 291]                  blk.9.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  89/ 291]                blk.9.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[  90/ 291]               blk.9.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  91/ 291]                blk.9.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[  92/ 291]                 blk.10.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  93/ 291]                 blk.10.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  94/ 291]                 blk.10.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  95/ 291]            blk.10.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[  96/ 291]               blk.10.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  97/ 291]                 blk.10.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  98/ 291]               blk.10.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[  99/ 291]              blk.10.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 100/ 291]               blk.10.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 101/ 291]                 blk.11.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 102/ 291]                 blk.11.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 103/ 291]                 blk.11.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 104/ 291]            blk.11.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 105/ 291]               blk.11.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 106/ 291]                 blk.11.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 107/ 291]               blk.11.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 108/ 291]              blk.11.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 109/ 291]               blk.11.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 110/ 291]                 blk.12.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 111/ 291]                 blk.12.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 112/ 291]                 blk.12.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[ 113/ 291]            blk.12.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 114/ 291]               blk.12.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 115/ 291]                 blk.12.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 116/ 291]               blk.12.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[ 117/ 291]              blk.12.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 118/ 291]               blk.12.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 119/ 291]                 blk.13.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 120/ 291]                 blk.13.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 121/ 291]                 blk.13.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 122/ 291]            blk.13.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 123/ 291]               blk.13.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 124/ 291]                 blk.13.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 125/ 291]               blk.13.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 126/ 291]              blk.13.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 127/ 291]               blk.13.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 128/ 291]                 blk.14.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 129/ 291]                 blk.14.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 130/ 291]                 blk.14.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 131/ 291]            blk.14.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 132/ 291]               blk.14.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 133/ 291]                 blk.14.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 134/ 291]               blk.14.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 135/ 291]              blk.14.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 136/ 291]               blk.14.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 137/ 291]                 blk.15.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 138/ 291]                 blk.15.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 139/ 291]                 blk.15.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[ 140/ 291]            blk.15.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 141/ 291]               blk.15.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 142/ 291]                 blk.15.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 143/ 291]               blk.15.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[ 144/ 291]              blk.15.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 145/ 291]               blk.15.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 146/ 291]                 blk.16.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 147/ 291]                 blk.16.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 148/ 291]                 blk.16.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 149/ 291]            blk.16.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 150/ 291]               blk.16.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 151/ 291]                 blk.16.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 152/ 291]               blk.16.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 153/ 291]              blk.16.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 154/ 291]               blk.16.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 155/ 291]                 blk.17.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 156/ 291]                 blk.17.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 157/ 291]                 blk.17.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 158/ 291]            blk.17.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 159/ 291]               blk.17.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 160/ 291]                 blk.17.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 161/ 291]               blk.17.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 162/ 291]              blk.17.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 163/ 291]               blk.17.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 164/ 291]                 blk.18.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 165/ 291]                 blk.18.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 166/ 291]                 blk.18.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[ 167/ 291]            blk.18.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 168/ 291]               blk.18.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 169/ 291]                 blk.18.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 170/ 291]               blk.18.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[ 171/ 291]              blk.18.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 172/ 291]               blk.18.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 173/ 291]                 blk.19.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 174/ 291]                 blk.19.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 175/ 291]                 blk.19.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 176/ 291]            blk.19.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 177/ 291]               blk.19.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 178/ 291]                 blk.19.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 179/ 291]               blk.19.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 180/ 291]              blk.19.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 181/ 291]               blk.19.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 182/ 291]                 blk.20.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 183/ 291]                 blk.20.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 184/ 291]                 blk.20.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 185/ 291]            blk.20.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 186/ 291]               blk.20.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 187/ 291]                 blk.20.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 188/ 291]               blk.20.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 189/ 291]              blk.20.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 190/ 291]               blk.20.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 191/ 291]                 blk.21.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 192/ 291]                 blk.21.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 193/ 291]                 blk.21.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[ 194/ 291]            blk.21.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 195/ 291]               blk.21.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 196/ 291]                 blk.21.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 197/ 291]               blk.21.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[ 198/ 291]              blk.21.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 199/ 291]               blk.21.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 200/ 291]                 blk.22.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 201/ 291]                 blk.22.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 202/ 291]                 blk.22.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 203/ 291]            blk.22.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 204/ 291]               blk.22.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 205/ 291]                 blk.22.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 206/ 291]               blk.22.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 207/ 291]              blk.22.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 208/ 291]               blk.22.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 209/ 291]                 blk.23.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 210/ 291]                 blk.23.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 211/ 291]                 blk.23.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 212/ 291]            blk.23.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 213/ 291]               blk.23.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 214/ 291]                 blk.23.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 215/ 291]               blk.23.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 216/ 291]              blk.23.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 217/ 291]               blk.23.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 218/ 291]                 blk.24.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 219/ 291]                 blk.24.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 220/ 291]                 blk.24.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[ 221/ 291]            blk.24.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 222/ 291]               blk.24.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 223/ 291]                 blk.24.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 224/ 291]               blk.24.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[ 225/ 291]              blk.24.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 226/ 291]               blk.24.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 227/ 291]                 blk.25.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 228/ 291]                 blk.25.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 229/ 291]                 blk.25.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 230/ 291]            blk.25.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 231/ 291]               blk.25.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 232/ 291]                 blk.25.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 233/ 291]               blk.25.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 234/ 291]              blk.25.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 235/ 291]               blk.25.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 236/ 291]                 blk.26.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 237/ 291]                 blk.26.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 238/ 291]                 blk.26.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 239/ 291]            blk.26.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 240/ 291]               blk.26.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 241/ 291]                 blk.26.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 242/ 291]               blk.26.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 243/ 291]              blk.26.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 244/ 291]               blk.26.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 245/ 291]                 blk.27.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 246/ 291]                 blk.27.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 247/ 291]                 blk.27.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[ 248/ 291]            blk.27.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 249/ 291]               blk.27.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 250/ 291]                 blk.27.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 251/ 291]               blk.27.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[ 252/ 291]              blk.27.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 253/ 291]               blk.27.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 254/ 291]                 blk.28.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 255/ 291]                 blk.28.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 256/ 291]                 blk.28.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[ 257/ 291]            blk.28.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 258/ 291]               blk.28.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 259/ 291]                 blk.28.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 260/ 291]               blk.28.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[ 261/ 291]              blk.28.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 262/ 291]               blk.28.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 263/ 291]                 blk.29.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 264/ 291]                 blk.29.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 265/ 291]                 blk.29.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[ 266/ 291]            blk.29.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 267/ 291]               blk.29.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 268/ 291]                 blk.29.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 269/ 291]               blk.29.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[ 270/ 291]              blk.29.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 271/ 291]               blk.29.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 272/ 291]                 blk.30.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 273/ 291]                 blk.30.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 274/ 291]                 blk.30.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[ 275/ 291]            blk.30.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 276/ 291]               blk.30.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 277/ 291]                 blk.30.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 278/ 291]               blk.30.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[ 279/ 291]              blk.30.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 280/ 291]               blk.30.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 281/ 291]                 blk.31.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 282/ 291]                 blk.31.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 283/ 291]                 blk.31.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n","[ 284/ 291]            blk.31.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n","[ 285/ 291]               blk.31.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 286/ 291]                 blk.31.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n","[ 287/ 291]               blk.31.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n","[ 288/ 291]              blk.31.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 289/ 291]               blk.31.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 290/ 291]                   output_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n","[ 291/ 291]                        output.weight - [ 3072, 32064,     1,     1], type =    f16, converting to q6_K .. size =   187.88 MiB ->    77.06 MiB\n","llama_model_quantize_internal: model size  =  7288.51 MB\n","llama_model_quantize_internal: quant size  =  2210.78 MB\n","\n","main: quantize time = 482114.40 ms\n","main:    total time = 482114.40 ms\n","Unsloth: Conversion completed! Output location: ./model/unsloth.Q4_K_M.gguf\n","Unsloth: Saved Ollama Modelfile to model/Modelfile\n"]}]},{"cell_type":"markdown","source":["Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in `Ollama` locally."],"metadata":{"id":"bDp0zNpwe6U_"}}],"metadata":{"colab":{"provenance":[{"file_id":"1jz8BV8lwN2YUwB7ZwJYals0eMvbGOT3z","timestamp":1720607604270}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ecb54928de454e3cb166451759df621d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7cada174322648d0b832733603f7d3f3","IPY_MODEL_e67e6001750e4f32969b78e337ff5c35","IPY_MODEL_1b4757bf17d24eb480bb55c815099cc4"],"layout":"IPY_MODEL_e8aa434a61eb4f3e86a86f583075e848"}},"7cada174322648d0b832733603f7d3f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58e3de1a35ed47b689b9c02378b3907f","placeholder":"​","style":"IPY_MODEL_c297dd752f6b4e9a8d684dea18bcdfc9","value":"config.json: 100%"}},"e67e6001750e4f32969b78e337ff5c35":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ba1362eddb64d92be61bbd4b522d4c0","max":1161,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c788a9fd01d400abfb6c1c207d85b71","value":1161}},"1b4757bf17d24eb480bb55c815099cc4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ab384c0619e48a69ce45ffb9b64feea","placeholder":"​","style":"IPY_MODEL_75938c714aef4e56a0669d44ed45c86e","value":" 1.16k/1.16k [00:00&lt;00:00, 37.2kB/s]"}},"e8aa434a61eb4f3e86a86f583075e848":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58e3de1a35ed47b689b9c02378b3907f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c297dd752f6b4e9a8d684dea18bcdfc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ba1362eddb64d92be61bbd4b522d4c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c788a9fd01d400abfb6c1c207d85b71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ab384c0619e48a69ce45ffb9b64feea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75938c714aef4e56a0669d44ed45c86e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfc3398b12944e8ca45de77fee3f8bde":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ab0a576acc54a52b41edf3dd527e0c2","IPY_MODEL_832c38cba77a4424be0683a755e63752","IPY_MODEL_a0b24efc14274f1ca826907035cda1f8"],"layout":"IPY_MODEL_a90eeb14c4924a699fba6fb76c213028"}},"6ab0a576acc54a52b41edf3dd527e0c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd4c84b9a73c4a8b82173710d8e2bf18","placeholder":"​","style":"IPY_MODEL_07eb6953fc694818ad97fe805758ff69","value":"model.safetensors: 100%"}},"832c38cba77a4424be0683a755e63752":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_875dd8bf08ff4b769ebd37ca2ee005c6","max":2264298471,"min":0,"orientation":"horizontal","style":"IPY_MODEL_98abd4f283eb4a71bba380731d02e2ab","value":2264298471}},"a0b24efc14274f1ca826907035cda1f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9d10a5ab5974eb29347885fb0fcde50","placeholder":"​","style":"IPY_MODEL_578f51ffd0b24c4abea968d9058df70e","value":" 2.26G/2.26G [00:18&lt;00:00, 219MB/s]"}},"a90eeb14c4924a699fba6fb76c213028":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd4c84b9a73c4a8b82173710d8e2bf18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07eb6953fc694818ad97fe805758ff69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"875dd8bf08ff4b769ebd37ca2ee005c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98abd4f283eb4a71bba380731d02e2ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9d10a5ab5974eb29347885fb0fcde50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"578f51ffd0b24c4abea968d9058df70e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f59d7c394546416f8e3a8fed76ee8b23":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_06189c45a0684162843f6baca0890775","IPY_MODEL_6d938d0e190a49abb96d1038a9cfe62f","IPY_MODEL_421853b4212a488396968b09df1750a0"],"layout":"IPY_MODEL_5ad40417128349c594d11fee87643dc4"}},"06189c45a0684162843f6baca0890775":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88f7ff57c4ab42538d15627b75accdbc","placeholder":"​","style":"IPY_MODEL_0c95d325e98e4312953f50e05b99f114","value":"generation_config.json: 100%"}},"6d938d0e190a49abb96d1038a9cfe62f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f303c47417da4177a8baab05646ab922","max":145,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b78888d264b047a5a0a9dea5847f709b","value":145}},"421853b4212a488396968b09df1750a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_615a32743d1b47de8f62dc373a15868c","placeholder":"​","style":"IPY_MODEL_0475d91e16f141088fa21fb5a6c253b8","value":" 145/145 [00:00&lt;00:00, 9.03kB/s]"}},"5ad40417128349c594d11fee87643dc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88f7ff57c4ab42538d15627b75accdbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c95d325e98e4312953f50e05b99f114":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f303c47417da4177a8baab05646ab922":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b78888d264b047a5a0a9dea5847f709b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"615a32743d1b47de8f62dc373a15868c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0475d91e16f141088fa21fb5a6c253b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2a08cc8a4f148d3a8e90c9f8dfbcc6d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e72e6bce06c400fb4a0eb38b192b14e","IPY_MODEL_49b6050493264265a4f8cffba3986611","IPY_MODEL_a524478330c14a2d84eaab4df24d5da7"],"layout":"IPY_MODEL_5fba2ae116cf4704ab42eac48eddf42d"}},"7e72e6bce06c400fb4a0eb38b192b14e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c80b40ef2ca4c7aa70f148b05d4a5de","placeholder":"​","style":"IPY_MODEL_25c3aaa1197f44b9bf2fd9a7f8ca9b13","value":"tokenizer_config.json: 100%"}},"49b6050493264265a4f8cffba3986611":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6213b6426a244d0396176ef6567e47a7","max":3342,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52ce5b84963a4f6da02e229a445485e6","value":3342}},"a524478330c14a2d84eaab4df24d5da7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_321ecf9ad90649aab410d6db0a88d198","placeholder":"​","style":"IPY_MODEL_45ed1bab2fda4b8b87a8a8864f64025f","value":" 3.34k/3.34k [00:00&lt;00:00, 156kB/s]"}},"5fba2ae116cf4704ab42eac48eddf42d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c80b40ef2ca4c7aa70f148b05d4a5de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25c3aaa1197f44b9bf2fd9a7f8ca9b13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6213b6426a244d0396176ef6567e47a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52ce5b84963a4f6da02e229a445485e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"321ecf9ad90649aab410d6db0a88d198":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45ed1bab2fda4b8b87a8a8864f64025f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ce7b66676744bceb179e7a1f84c147d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6cc1542b6f284cc9be2aba908789907d","IPY_MODEL_2705ef50e16142d4b583ec7ec3fd334b","IPY_MODEL_a907d7d6f7804ce8acf2d817270d713a"],"layout":"IPY_MODEL_5d22fd7b8b2445bd8c217a81d1d35ed9"}},"6cc1542b6f284cc9be2aba908789907d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd4b8747d3e947acbfe1f525ed37b63c","placeholder":"​","style":"IPY_MODEL_b52529c214bb4e868f5903a572a18586","value":"tokenizer.model: 100%"}},"2705ef50e16142d4b583ec7ec3fd334b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2af1903c0f5d437f9ffa45c38e8a4976","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00da24866156472099a57b21f8c2d4a2","value":499723}},"a907d7d6f7804ce8acf2d817270d713a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0874e760feac4cbe98ae01373cdac836","placeholder":"​","style":"IPY_MODEL_2abb0244377448d5b5ad1262b283d194","value":" 500k/500k [00:00&lt;00:00, 30.1MB/s]"}},"5d22fd7b8b2445bd8c217a81d1d35ed9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd4b8747d3e947acbfe1f525ed37b63c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b52529c214bb4e868f5903a572a18586":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2af1903c0f5d437f9ffa45c38e8a4976":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00da24866156472099a57b21f8c2d4a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0874e760feac4cbe98ae01373cdac836":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2abb0244377448d5b5ad1262b283d194":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b52e96f245d541af91fbc390b4734dcc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a420153017c54469bf62ae021b72b1c8","IPY_MODEL_3250ab192f2a4aef8188f411a8c0ba58","IPY_MODEL_786a2b507e5647ffa1e2be719d66b48d"],"layout":"IPY_MODEL_7cac5229850a49f0a4e3f0089c509eae"}},"a420153017c54469bf62ae021b72b1c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bb8d5c0c668443a9763c8290b789249","placeholder":"​","style":"IPY_MODEL_f92463dfa95a404f84bde240673efab0","value":"added_tokens.json: 100%"}},"3250ab192f2a4aef8188f411a8c0ba58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_21c571f0150646aaa38bc2f31ffa1fc5","max":293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b63b65eac5e541ad9269069cb0b3f905","value":293}},"786a2b507e5647ffa1e2be719d66b48d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5784fe1769b44718ba6b2a1e3171961","placeholder":"​","style":"IPY_MODEL_3bcae41373ff4474a475287366dd4d9e","value":" 293/293 [00:00&lt;00:00, 21.2kB/s]"}},"7cac5229850a49f0a4e3f0089c509eae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bb8d5c0c668443a9763c8290b789249":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f92463dfa95a404f84bde240673efab0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21c571f0150646aaa38bc2f31ffa1fc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b63b65eac5e541ad9269069cb0b3f905":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5784fe1769b44718ba6b2a1e3171961":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bcae41373ff4474a475287366dd4d9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4191994160274dfd83794ce3326d63e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a4420b571a44d82aac1b0a85d9cc04a","IPY_MODEL_7d1cfb105a5847ab9102d02c8ef8c6f3","IPY_MODEL_b2c38dfd9fa145d58193eb15c1958ca2"],"layout":"IPY_MODEL_b82994f24ab6426490e8c89f10eb9865"}},"7a4420b571a44d82aac1b0a85d9cc04a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0bcf3f98ddf451583391a6dbca48b47","placeholder":"​","style":"IPY_MODEL_cfdc342fcf6e4cafa6fd75fae9bc4173","value":"special_tokens_map.json: 100%"}},"7d1cfb105a5847ab9102d02c8ef8c6f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9007b297d26346d196898b42f627f4b2","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b65a029c795f44b48098866776f393e7","value":571}},"b2c38dfd9fa145d58193eb15c1958ca2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f3eb6b6bb734a76980ac6cdc5fb848b","placeholder":"​","style":"IPY_MODEL_b6deb20d34794fc7b6e27f1f212455e9","value":" 571/571 [00:00&lt;00:00, 36.7kB/s]"}},"b82994f24ab6426490e8c89f10eb9865":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0bcf3f98ddf451583391a6dbca48b47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfdc342fcf6e4cafa6fd75fae9bc4173":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9007b297d26346d196898b42f627f4b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b65a029c795f44b48098866776f393e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f3eb6b6bb734a76980ac6cdc5fb848b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6deb20d34794fc7b6e27f1f212455e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c437d763b844a548899160de10ba83c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c927ddda9ebc497e8dedcad23862a933","IPY_MODEL_bc9dfbd2f5614e59871f4b35a36f8593","IPY_MODEL_c3206c6fec394afbb0ab16f9fcba0336"],"layout":"IPY_MODEL_4155549030cf431284b59534f48e3e03"}},"c927ddda9ebc497e8dedcad23862a933":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_682a25bf44104cb4b2325a06884ae72b","placeholder":"​","style":"IPY_MODEL_6bb0a8d8077542288cd1c704ca5f8a43","value":"tokenizer.json: 100%"}},"bc9dfbd2f5614e59871f4b35a36f8593":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5050229144c74ad3987ab464e0efa55e","max":1844436,"min":0,"orientation":"horizontal","style":"IPY_MODEL_025261c18b3d41d880e3b68646f6436e","value":1844436}},"c3206c6fec394afbb0ab16f9fcba0336":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_774c6fcb33554f35ba2100401b362e92","placeholder":"​","style":"IPY_MODEL_dd8fda5b550f417db9599618bc3ccc81","value":" 1.84M/1.84M [00:00&lt;00:00, 5.67MB/s]"}},"4155549030cf431284b59534f48e3e03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"682a25bf44104cb4b2325a06884ae72b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bb0a8d8077542288cd1c704ca5f8a43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5050229144c74ad3987ab464e0efa55e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"025261c18b3d41d880e3b68646f6436e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"774c6fcb33554f35ba2100401b362e92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd8fda5b550f417db9599618bc3ccc81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8151caecef784930accc862a9ee80c03":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9de35da4ae194ee7838707bbf6d635db","IPY_MODEL_d60447c9b2a241a3a7d0186a92b6e42b","IPY_MODEL_b125392e1953429597c77337b7336875"],"layout":"IPY_MODEL_d7c64f3c502a4d6d992fc7201a0248ce"}},"9de35da4ae194ee7838707bbf6d635db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f697013eb6174007ac8aed6e84777370","placeholder":"​","style":"IPY_MODEL_9a4fd5dbec0b4554a4ee024a463c9f66","value":"Map: 100%"}},"d60447c9b2a241a3a7d0186a92b6e42b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_54b610ddee504ba7a86abed639076ed5","max":1558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e6bd23b13b342f6afdc9867999bcf24","value":1558}},"b125392e1953429597c77337b7336875":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4c4a63025cf48a38cf324803d28d31a","placeholder":"​","style":"IPY_MODEL_6fc2568e20d94f92a3011b1ff11dadb9","value":" 1558/1558 [00:00&lt;00:00, 5176.82 examples/s]"}},"d7c64f3c502a4d6d992fc7201a0248ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f697013eb6174007ac8aed6e84777370":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a4fd5dbec0b4554a4ee024a463c9f66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54b610ddee504ba7a86abed639076ed5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e6bd23b13b342f6afdc9867999bcf24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4c4a63025cf48a38cf324803d28d31a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fc2568e20d94f92a3011b1ff11dadb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"969cdc6c53c44106b5dfd04163ebb73b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99ecdb5d66c54e5f815b615b02697c90","IPY_MODEL_5405ea42a23e41dd9776f0d21ad6f30b","IPY_MODEL_bff6bb26648b41e89045c7d4c1f28b2d"],"layout":"IPY_MODEL_41a11f975ed0487b99316f08db7b1f9d"}},"99ecdb5d66c54e5f815b615b02697c90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0ddf583dfa54252aefa245c423ba55b","placeholder":"​","style":"IPY_MODEL_939db90a05344cdf8e8c2c1cebe416ea","value":"Map (num_proc=2): 100%"}},"5405ea42a23e41dd9776f0d21ad6f30b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_040fc26e217a453b80ac472029c234fa","max":1558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e85ad43898c4aee97c51f657b4521fa","value":1558}},"bff6bb26648b41e89045c7d4c1f28b2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4450c45ce67e459d89af5ff7e2cdec8c","placeholder":"​","style":"IPY_MODEL_eedbc0a783ae499db467f391ceaf35a7","value":" 1558/1558 [00:00&lt;00:00, 973.62 examples/s]"}},"41a11f975ed0487b99316f08db7b1f9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0ddf583dfa54252aefa245c423ba55b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"939db90a05344cdf8e8c2c1cebe416ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"040fc26e217a453b80ac472029c234fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e85ad43898c4aee97c51f657b4521fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4450c45ce67e459d89af5ff7e2cdec8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eedbc0a783ae499db467f391ceaf35a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}